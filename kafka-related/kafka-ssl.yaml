# This article describes the steps you need to take to enable SSL for Kafka clients. This is written to be implemented in Spring micro-services, 
# but could also serve as a guide for other Kafka related applications.

# For Kafka we have decided that we use mTLS, that means that both the server and the client hold a certificate that is signed by the CA. On establishing the connection, 
# both the broker checks the client certificate, and the client checks the broker certificate. The checking is done by checking whether the certificate is signed by a CA 
# that we have in the trust-store. On the client side, we also check that the bootstrapserver address is in the SAN part of the certificate.

# To get it to work in our micro-services we consider the following:
# Certificates and keys are mounted automatically in K8, We want to create a trust-store with just the CA in it
# We propagate these locations of trust- and key-store and passwords to the application.
# Change bootstrap server to the address that is in the SAN part of the certificate. This should give the list.

# Init Container
# The initcontainer can be used as in this example repository.
# We mount an initcontainer as such, we add this to the values.yaml in the helm-chart (this creates the truststore):

volumeMounts:
  - name: truststore-dyns
    mountPath: /trust

volumes:
  - name: truststore-dyns


initContainers:
  - name: convert-key
    image: "{{ .Values.image.repository }}:{{ .Values.service.version }}"
    command: [ 'sh', '-c', 'keytool -importcert -alias dyns -keystore /result/dyn.jks -storepass changeit -file /tls/root_ca.der -noprompt']
    volumeMounts:
      - mountPath: /result
        name: truststore-dyns

#  import a certificate into a Java KeyStore (JKS)
# -importcert: Imports a certificate into a keystore.
# -alias dyns: Sets the alias of the certificate as dyns (use a unique alias if you plan to store multiple certificates)
# -keystore /result/dyn.jks: Specifies the keystore file where the certificate will be stored (dyn.jks in the /result/ directory)
#       Keystore Existence: If /result/dyn.jks does not exist, keytool will create it.
# -storepass changeit: Uses changeit as the password for the keystore (this is the default password for Java keystores; you should change it for security reasons).
# -file /tls/root_ca.der: Specifies the certificate file to be imported (root_ca.der in the /tls/ directory). Ensure the certificate is in the correct format (DER-encoded binary X.509 certificate).
# -noprompt: Automatically confirms the import without prompting the user.


# We added the following things to our application.yaml:
spring:
  kafka:
    bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS:localhost:9092}
    ssl:
      key-store-location: file:///tls/store.p12
      key-store-password: ${TLS_CERT_STORE_PASSWORD}
      key-store-type: PKCS12
      trust-store-location: file:///trust/dyn.jks
      trust-store-password: changeitzz
    producer:
      value-serializer: io.confluent.kafka.serializers.KafkaAvro
    properties:
      security.protocol: SSL


# this is where scraping addresses and alert manager specifictions are defined
global:
  scrape_interval: 30s
  scrape_timeout: 10s
  scrape_protocols:
  - OpenMetricsText1.0.0
  - OpenMetricsText0.0.1
  - PrometheusText0.0.4
  evaluation_interval: 30s
  external_labels:
    aws_account_name: DEV
    env: dev
    k8scluster: dn-dev-vt
    prometheus: monitoring/prometheus
    prometheus_cluster_replica: prometheus-prometheus
    prometheus_replica: prometheus-prometheus-0
    region: eu-west-2
alerting:
  alert_relabel_configs:
  - separator: ;
    regex: prometheus_replica
    replacement: $1
    action: labeldrop
  alertmanagers:
  - tls_config:
      ca_file: /etc/ssl/certs/tls-ca-bundle.pem
      insecure_skip_verify: false
    follow_redirects: true
    enable_http2: true
    scheme: https
    timeout: 10s
    api_version: v2
    static_configs:
    - targets:
      - alertmanager-0.dmon.dyns.dev.eu-west-1.aws.mycorps.net:443
      - alertmanager-1.dmon.dyns.dev.eu-west-1.aws.mycorps.net:443
rule_files:
- /etc/prometheus/rules/prometheus-prometheus-rulefiles-0/*.yaml
scrape_configs:
- job_name: serviceMonitor/105642-core-vt/vt/0
  honor_timestamps: true
  track_timestamps_staleness: false
  scrape_interval: 30s
  scrape_timeout: 10s
  scrape_protocols:
  - OpenMetricsText1.0.0
  - OpenMetricsText0.0.1
  - PrometheusText0.0.4
  metrics_path: /v1/sys/metrics
  scheme: https
  enable_compression: true
  tls_config:
    insecure_skip_verify: true
  follow_redirects: true
  enable_http2: true
  relabel_configs:
  - source_labels: [job]
    separator: ;
    regex: (.*)
    target_label: __tmp_prometheus_job_name
    replacement: $1
    action: replace
  - source_labels: [__meta_kubernetes_service_label_global_service, __meta_kubernetes_service_labelpresent_global_service]
    separator: ;
    regex: (true);true
    replacement: $1
    action: keep
  - source_labels: [__meta_kubernetes_endpoint_port_name]
    separator: ;
    regex: api-port
    replacement: $1
    action: keep


# Known issues:
# pipeline might throw errors due to issues downloading the AWS or Kubernetes provider. re-running the pipeline again will fix these issues.

# Known limitations

# cert-manager has a hard limit on the CN length. Therefore, the total length of deployment name + namespace name cannot exceed 63 characters.
# We have a kyverno policy which will prevent any deployments which violate this rule.
# Enable mTLS for new Kafka client app
# To enable new certificates, we need to add the next annotations to your Deployment/StatefulSet/Job:

metadata:
  name: test-service
  namespace: test
  annotations:
    dyn.certificate.tls/active: "false"  # this annotation will disable old PCA webhook
    dyn.certificate.cdb/client: "false"  # this annotation will disable old PCA webhook for CDB
    pca.ics.tls/active: "true"           # this annotation will enable new PCA webhook

# Certificates will be generated automatically for K8S Deployments, StatefulSets and Jobs and will be mounted into each pod by mutating web hook.
# Certificates will be located inside /certs/ subfolder inside each container within the pod.

# List of available certificates/keys:
ls /certs/
ca.crt  key.der  keystore.jks  keystore.p12  tls.crt  tls.key  truststore.jks  truststore.p12
# So, all we need to do is to configure an application to use them

In your application.yaml file, use the following parameters:

spring:
  kafka:
    bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS:core-kafka.105250-kafka.svc.cluster.local:9092}
    ssl:
      key-store-location: file:///certs/keystore.p12
      key-store-password: ${CERT_KEY_STORE_PASSWORD}
      key-store-type: PKCS12
      trust-store-location: file:///certs/truststore.p12
      trust-store-password: ${CERT_KEY_STORE_PASSWORD}
    producer:
      value-serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
    properties:
      schema.registry.url: ${SCHEMA_REGISTRY_URL:https://core-schema-registry.35987-kafka.svc.cluster.local:8081}
      schema.registry.ssl.truststore.location: /certs/truststore.p12
      schema.registry.ssl.truststore.password: ${CERT_KEY_STORE_PASSWORD}
      schema.registry.ssl.keystore.location: /certs/keystore.p12
      schema.registry.ssl.keystore.password: ${CERT_KEY_STORE_PASSWORD}
      schema.registry.ssl.keystore.type: PKCS12
      security.protocol: SSL
      ssl.endpoint.identification.algorithm: ${KAFKA_HTTPS:https}

# We use the same password to encrypt the trust store and key store in p12 and jks formats.
# That password is available as a CERT_KEY_STORE_PASSWORD environment variable and will be generated and injected into your pod automatically by mutating the webhook.
# These certificates are in PEM format and private key encoding in PKCS#1 or PKCS#8 and PKCS#12 (JKS) format. The connectivity test to CDB using the cockroach command 
# line tool